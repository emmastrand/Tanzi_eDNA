---
title: "Datatable preparation base script for eDNA metabarcoding"
output:
  github_document: default
  pdf_document:
    keep_tex: yes
  html_document:
    toc: yes
    toc_depth: 6
    toc_float: yes
editor_options: 
  chunk_output_type: inline
---

**.Rmd script** 

Example data from [Polinski et al., 2025](https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.70138)

This script takes your Blast output from the GMGI database, Mitofish database, and NCBI database to create one datatable with read counts and taxonomic assignment.  

**Workflow summary:**  
1. Load libraries   
2. Load metadata     
3. Load BLAST output from GMGI, Mitofish, and NCBI     
4. Load DADA2 ASV Table    
5. Taxonomic Assignment  
  - 5a. Identify ASVs with multiple hits from GMGI's database    
  - 5b. Identify entries that mismatch between GMGI, Mitofish, and NCBI databases   
  - 5c. Assign taxonomy based on hierarchical approach  
  - 5d. Edit taxonomy annotations based on mismatch table choices  
  - 5e. Adjusting common name and category for those entries that don't have one (from Mito or NCBI)  
6. Filtering: Filter ASV by less than 0.1% reads and then collapse by group  
7. Collapsing read counts by species name  
8. Creating results output 


## Load libraries

```{r}
library(ggplot2) ## for plotting
library(dplyr) ## for data table manipulation
library(tidyr) ## for data table manipulation
library(readr) ## for reading in tsv files
library(readxl) ## for reading in excel files
library(stringr) ## for data transformation
library(strex) ## for data transformation
library(writexl) ## for excel output
library(purrr) ## for data transformation
library(funrar) ## for make_relative()
library(tidyverse) ## for data table manipulation
library(Biostrings) ## for reading in fasta file 
library(data.table)  ## for data table manipulation
```

## Metadata input

### Identify paths for metadata and project data 

Each user needs to write in their specific directory outputs prior to the file name. The default working directory is this document so the folder where this script is saved for the user. To change the workign directory to the Rproject directory, select 'Knit' and 'Knit Directory' > 'Project Directory'.

```{r}
### User edits:
### 1. change paths of input and output as desired 

## BLAST results
path_blast_ncbi_taxassigned = "../year2_data/NCBI_taxassigned.txt"
path_blast_ncbi = "../year2_data/BLASTResults_NCBI.txt"

## ASV table results 
## confirm that the ASV_table.len.tsv name is correct for user's project
path_asv_table = "../year2_data/ASV_table.tsv"
path_seq_file = "../year2_data/ASV_seqs.fasta"
path_output_summary = "../year2_data/overall_summary.tsv"
```

### Project metadata

```{r}

```


## BLAST data input 

No user edits unless user changed blastn parameters from fisheries team default.

```{r}
## Setting column header names and classes
blast_col_headers = c("ASV_ID", "sseqid", "pident", "length", "mismatch", "gapopen",
                                        "qstart", "qend", "sstart", "send", "evalue", "bitscore")
blast_col_classes = c(rep("character", 2), rep("numeric", 10))
```

### NCBI database 

No user edits.

```{r}
NCBI_taxassigned <- read.delim2(path_blast_ncbi_taxassigned, header=F, col.names = c("staxid", "Phylo")) %>%
  ## creating taxonomic assignment columns
  separate(Phylo, c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species_name"), sep = ";") %>%
  ## creating species column based on Species_name
  mutate(., species = str_after_nth(Species_name, " ", 1))

Blast_NCBI <- read.table(path_blast_ncbi, header=F,
                           col.names = c("ASV_ID", "sseqid", "sscinames", "staxid", "pident", "length", "mismatch",
                                         "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore"),
                           colClasses = c(rep("character", 3), "integer", rep("numeric", 9))) %>%
  left_join(., NCBI_taxassigned, by = "staxid")
```

## Load DADA2 ASV Table 

The column headers will be the Sample IDs and the first column is the ASV ID. ASVs are given a "rank" based on sum of reads from that ASV (pre-filtering). 'Random' indicates that if ASVs are tied, then the code will randomly assign a rank for those tied. Because we don't need an exact rank here, 'random' will do for a tie-breaker.

No user edits.

1,034 ASVs ...

```{r}
ASV_table <- read_tsv(path_asv_table, show_col_types = FALSE) %>%
  ## calculate the sum of all reads for each ASV
  mutate(., ASV_sum = rowSums(across(where(is.numeric)))) %>% 
  
  ## calculate a ranking based on those sum calculated above
  mutate(ASV_rank = rank(-ASV_sum, ties.method='random')) %>%
  
  ## move the sum and rank columns to after ASV_ID and arrange by rank
  relocate(c(ASV_sum,ASV_rank), .after = ASV_ID) %>% arrange((ASV_rank)) %>%
  
  ## editing the rank value to be out of the max # 
  mutate(ASV_rank = paste0(ASV_rank, "/", max(ASV_rank, na.rm = TRUE)))

## creating list of rankings
ASV_rank_list <- ASV_table %>% dplyr::select(ASV_ID, ASV_sum, ASV_rank)
```

## Taxonomic Assignment

```{r}
Blast_NCBI_top <- Blast_NCBI %>%
  dplyr::group_by(ASV_ID) %>%
  dplyr::select(ASV_ID, pident, length, Kingdom:species) %>%
  dplyr::filter(!(Kingdom == "Eukaryota" & Phylum == "Unassigned")) %>%
  dplyr::slice_max(pident, n = 1) %>%
  dplyr::distinct()

length(unique(Blast_NCBI_top$ASV_ID))

## Multiple choices 
ASV_multi_rows <- Blast_NCBI_top %>%
  dplyr::group_by(ASV_ID) %>%
  dplyr::filter(dplyr::n() > 1)

ASV_multi_rows %>% write_xlsx("../year2_data/Multiple_choice.xlsx")
```

```{r}
multiple_hit_choice_edited <- read_xlsx("../year2_data/Multiple_choice_edited.xlsx") %>%
  filter(!is.na(Choice)) %>% 
  select(ASV_ID, Kingdom:species)   # only the taxonomy to overwrite

Blast_NCBI_top_edited <- Blast_NCBI_top %>% dplyr::select(-pident, -length) %>%
  rows_update(
    multiple_hit_choice_edited,
    by = "ASV_ID"
  ) %>% distinct()

Blast_NCBI_top_edited ##266 ASVs that had to pick from for multiple hits 
length(unique(Blast_NCBI_top_edited$ASV_ID))

## confirming all have one assignment 
Blast_NCBI_top_edited %>% group_by(ASV_ID) %>% count() %>% filter(n>1)
```

## Joining tax ID and filtering 

```{r}
ASV_table_taxID <- ASV_table %>% 
  
  ## 3. NCBI database; same functions as above
  right_join(Blast_NCBI_top_edited, .) %>%
  
  ### Filtering under 10 reads total for the ASV retains 877 ASVs 
  filter(ASV_sum > 10)

length(unique(ASV_table_taxID$ASV_ID))
```

## Exporting data frame 

```{r}
ASV_table_taxID %>% write_xlsx("../year2_data/results.xlsx")
```

